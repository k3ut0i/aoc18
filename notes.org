* Notes
** Day 03
If iterating over an array of more than one dimension, *row-major-index* and *row-major-aref* may help by iterating over just one variable.

#+BEGIN_SRC lisp
  (defparameter a (make-array (list 10 10)))

  (dotimes (x 10)
    (dotimes (y 10)
      (setf (aref a x y) (random 10))))

  (loop :for i :below (array-total-size a)
       :maximizing (row-major-aref a i))
#+END_SRC

#+RESULTS:
: 9

** Day 04
get-max and other related functions could be just inlined, if I used reduce.
If iterating for a single value, just use reduce or find or something similar. Do go all the way to loop for simple iterations.

** Day 05
I should've used char-equal to compare characters ignoring case. That would've improved flow of in both trigger-poly and remove-if(part2).
#+BEGIN_SRC lisp
  (char-equal #\A #\a)
#+END_SRC

#+RESULTS:
: T

** Day 09
For part 1 the using a list as a circle buffer sufficed. But most expensive operations in this problem seem to be insert and delete in the circle buffer. 
*** Part 1
First attempt stats
#+BEGIN_EXAMPLE
Evaluation took:
  5.658 seconds of real time
  5.662797 seconds of total run time (5.442621 user, 0.220176 system)
  [ Run times consist of 0.703 seconds GC time, and 4.960 seconds non-GC time. ]
  100.09% CPU
  9,596,470,454 processor cycles
  1,066,784,032 bytes consed
#+END_EXAMPLE

Worse with a lot of rplacd and setf cdrs. This implementation still exists as a reference to using destructive list operations. I haven't used them before. 
#+BEGIN_EXAMPLE
Evaluation took:
  24.966 seconds of real time
  24.965778 seconds of total run time (24.965647 user, 0.000131 system)
  100.00% CPU
  42,344,029,675 processor cycles
  3,276,800 bytes consed
#+END_EXAMPLE
I think last function was the problem. Must learn profiling.
So there is a reason when people say don't optimize blindly without looking for bottle necks.
*** Part 2.
I have tried implementing this in *c* using circular doubly linked lists. It's a bit buggy, but runtime is awesome. Keep in mind the above lisp runtimes are for _71522_ Not _7152200_ given below.
#+BEGIN_EXAMPLE
./day09_02 446 7152200  0.53s user 0.15s system 99% cpu 0.682 total
#+END_EXAMPLE
[2018-12-11 Tue] My c solution for 71522 steps(and all the other examples) works perfectly. But for 7152200, answer just returned 0. After printing all the scores I've noticed that they were negative. This was my first case of integer overflow and wrap around. Using *long long* instead of int to store my scores solved the problem.

#+BEGIN_EXAMPLE
Maxscore: 3277920293
./day09_02 446 7152200  0.58s user 0.09s system 99% cpu 0.674 total
#+END_EXAMPLE

** Day 11

For a given size *s* and Grid size *S*. The number of calculations for finding maximum power withing a square of size *s* is \( (S - s)^2 \times (s\times s -1) \).


This implementation runs for tens of minutes without reaching size 100, so it will likely run for more than an hour.

Given that there are no more than 300*300 elements in the grid, there are a lot of redundant calculations taking place. For any give power square size *s*, the calculations are always sequential additions. So if we accumulate the sum of all previous columns in each cell of the grid, the sum of a given power square is the sum of row-sums, row-sums are the difference b/w the last cell and cell-before first. so we can cut down the number of calculations to \( (S - s)^2 \times (2 \times s - 1) \), an order less.

#+BEGIN_SRC R :results file :var fname="day11-cals-best.jpeg" :exports both
  jpeg(filename=fname,
       width=640, height=480, units="px", pointsize=12,
       quality=75,
       bg="white", res=NA)
  size <- seq(1, 300)
  calsBad <- (300 - size)^2 * (size^2 - 1)
  cals <- (300 - size)^2 * (2*size - 1)
  plot(size, calsBad, xlab="Power square size", ylab="Number of calculations",
       col="red", pch=19,
       main="Operations for a given square size",
       ylim=range(c(calsBad, cals)))
  par(new = TRUE)
  plot(size, cals, xlab="Power square size", ylab="Number of calculations",
       col="green", pch=20,
       ylim=range(c(calsBad, cals)))
  legend(x="topleft", legend=c("Unoptimized", "Optimized"),
	 col=c("red", "green"), pch=c(19, 20))
  fname
#+END_SRC

#+RESULTS:
[[file:day11-cals-best.jpeg]]

The run time for the improved implementation is around 51 secs.
#+BEGIN_EXAMPLE
  CL-USER> (time (part2 1309))
  Evaluation took:
    50.156 seconds of real time
    50.162501 seconds of total run time (50.102278 user, 0.060223 system)
    [ Run times consist of 0.251 seconds GC time, and 49.912 seconds non-GC time. ]
    100.01% CPU
    85,066,931,941 processor cycles
    1,897,395,792 bytes consed  
  108
  (233 271)
  13
#+END_EXAMPLE

** Day 12
Part 1 was a straight forward solution but my solution in handling growth at both ends was a bit inelegant. It took me a while to notice how big a number fifty billion is. But my solution is pretty straight forward without any multidimensional loops, so how can i optimize? A simple solution exists only if this game of life stabilizes. After plotting the data for some generations we can notice that *sum of pots* is an arithmetic sequence after some point, so it is just shifting to the right with a period 1.

So the answer is C + (50000000000 - tc) * d. where *C* is the pots alive at time *tc* and *d* is the constant difference b/w generations.

#+BEGIN_SRC R :var input="day12_generation_data.txt" :var output="day12_plot.jpeg" :results value file :exports results 
  jpeg(filename=output,
       width=640, height=480, units="px", pointsize=12,
       quality=75,
       bg="white", res=NA)
  data <- read.table(file=input)
  plot(data, xlab="nth generation", ylab="sum of no of pots alive",
       main="Pots alive in a generation", col="red", type="l", lty=1, lwd=2)
  abline(1023,186, lty=2)
  legend(x="topleft", legend=c("gen data", "slope"), col=c("red", "black"),
	 lty=c(1,2))
  output
#+END_SRC

#+RESULTS:
[[file:day12_plot.jpeg]]

** Day 14
Memory problems for the first time. Previously it was always the problem with time constraints. SBCL throws a heap exhaustion error. I need to optimize the allocated array so it can just contain the digits. *char* should suffice, but 4 bits is just enough. Is there a way to handle fine grained memory constraints in lisp?

Setting the array allocation to (unsigned-byte 4) for 4 bits of space worked out.

#+BEGIN_EXAMPLE
  CL-USER> (time (part2 "540561" 50000000))
  Evaluation took:
    22.250 seconds of real time
    22.253924 seconds of total run time (22.003979 user, 0.249945 system)
    [ Run times consist of 0.153 seconds GC time, and 22.101 seconds non-GC time. ]
    100.02% CPU
    37,737,461,424 processor cycles
    1,379,115,728 bytes consed
  
  20254833
#+END_EXAMPLE

** Day 15
[2018-12-16 Sun]
First example works out perfectly.
#+BEGIN_EXAMPLE
  #######
  #G....#
  #.G...#
  #.#.#G#
  #...#.#
  #....G#
  #######
  (5 . 5) G[200]
  (2 . 2) G[131]
  (5 . 3) G[59]
  (1 . 1) G[200]
  Elves: 0 Goblins: 4

  47
#+END_EXAMPLE
For the second example my solution takes 38(37) rounds and one elf health is 188(185). So I'm missing an attack turn somewhere. The last goblin should have died one turn earlier and the elf should have taken one more hit.
#+BEGIN_EXAMPLE
  #######
  #...#E#
  #E#...#
  #.E##.#
  #E..#E#
  #.....#
  #######
  (5 . 1) E[200]
  (2 . 3) E[188]
  (1 . 4) E[200]
  (1 . 2) E[197]
  (5 . 4) E[200]
  Elves: 5 Goblins: 0

  38
#+END_EXAMPLE
For the third example my solution takes 51(46) rounds and all elves survive. Where as in the example one elf dies. The whole movement pattern seems to be wrong. I should recheck my path finding algorithms. 
#+BEGIN_EXAMPLE
  #######
  #.E.E.#
  #.#..E#
  #E.##E#
  #.E.#.#
  #...#.#
  #######
  (4 . 1) E[50]
  (5 . 2) E[200]
  (1 . 3) E[98]
  (5 . 3) E[200]
  (2 . 4) E[200]
  (2 . 1) E[98]
  Elves: 6 Goblins: 0

  51
#+END_EXAMPLE
Fifth example isn't terminating quickly.

I need to spend more time in writing a robust path finding algorithm.

** Day16
I wanted to write all opcode functions as macro definitions.
Something like
#+BEGIN_SRC lisp
  (defop "mulr" (a b c) (seti c (* (reg a) (reg b))))
  (defop "muli" (a b c) (seti c (* (reg a) b)))
#+END_SRC
But I'm not familiar enough with macros to do it quickly. So I had to go the symbol searching route to find the matching functions.
Run times.
#+BEGIN_EXAMPLE
  CL-USER> (time (part2 "input_16.txt" "input_16_program.txt"))
  Evaluation took:
    0.129 seconds of real time
    0.128454 seconds of total run time (0.088230 user, 0.040224 system)
    [ Run times consist of 0.059 seconds GC time, and 0.070 seconds non-GC time. ]
    99.22% CPU
    219,413,211 processor cycles
    16,417,712 bytes consed
  
  #(667 667 3 2)
#+END_EXAMPLE

** Day17
I tried to re-implement the flowing part as a part of backtracking solution using just recursive functions. But the runtime is horrible. Stack and heap exhaustion for the given input. I tried with almost a 1GB of stack size and 3GB of heap size
#+BEGIN_EXAMPLE
  sbcl --control-stack-size 1000  --dynamic-space-size 3072
#+END_EXAMPLE 

But heap is still exhausted. Logic dictates my program is correct, but Lisp isn't really suitable for this kind of logic. I should have tried to write my program more imperatively.
Sample problem works perfectly so I'll try to another implementation later.

** Day18
   By plotting the resource value after n minutes, we can see that resource value converges to a band gap. 
#+BEGIN_SRC R :var input="day18_data.txt" :var output="day18_plot.jpeg" :results value file :exports results 
  jpeg(filename=output,
       width=640, height=480, units="px", pointsize=12,
       quality=75,
       bg="white", res=NA)
  data <- read.table(file=input)
  plot(data, xlab="nth minute", ylab="resource value",
       main="Resource value in time", col="blue", type="l", lty=1, lwd=2)
  output
#+END_SRC

#+RESULTS:
[[file:day18_plot.jpeg]]

Lets try zooming in after at the end

#+BEGIN_SRC R :var input="day18_data.txt" :var output="day18_plot2.jpeg" :results value file :exports results 
  jpeg(filename=output,
       width=640, height=480, units="px", pointsize=12,
       quality=75,
       bg="white", res=NA)
  data <- read.table(file=input)
  dataZoomed <- subset(data, data$V1 >= 9500)
  plot(dataZoomed, xlab="nth minute", ylab="resource value",
       main="resource value time line", col="green", type="l", lty=1, lwd=2)
  output
#+END_SRC

#+RESULTS:
[[file:day18_plot2.jpeg]]

In a hundred minute interval the resource value fluctuates more than 3 times.
So I'm assuming the period is less than 30 minutes. Looking at the tail end of the data generated I've noticed that 9970 has 189994 and 9998 again has 189994. So the period is 28 minutes.
#+BEGIN_SRC elisp :exports both
  (let ((diff (- 1000000000 9970)))
    (mod diff 28))
#+END_SRC

#+RESULTS:
: 18

So the Resource value is the same as at 9970 + 18 = 9988 i.e., 190162.
That was the wrong answer? why?
Hmm, the data in analysis file is zero indexed so we need one less minutes resource value. so the value of 9987 i.e., 190820

** Day19
I took most of the opcode implementation stuff from day16 problem.
Part 1 run time.
#+BEGIN_EXAMPLE
  (time (run-prog (read-program "input_19.txt")))
  Evaluation took:
    1.818 seconds of real time
    1.818684 seconds of total run time (1.818684 user, 0.000000 system)
    100.06% CPU
    3,084,659,125 processor cycles
    32,768 bytes consed
  
  #(1530 1019 1018 257 1019 1)
#+END_EXAMPLE

Part 2 is taking very long. Why?. I think it's looping over very large end condition. I should take a look at how the register values are changing.

Instructions are just looping mostly around 3,4,5,6, 8,9,10,11 instructions. Let us look at these instructions.
#+BEGIN_EXAMPLE
  01  seti 1 3 1  reg1 = 1
  02  seti 1 2 4  reg4 = 1
  03  mulr 1 4 5  reg5 = reg4 * reg1
  04  eqrr 5 2 5  reg5 eq reg2
  05  addr 5 3 3  If above true then goto 07
  06  addi 3 1 3  else goto 08
  07  addr 1 0 0  reg0 = reg0 + reg1, i.e., accumulate the factor reg1
  08  addi 4 1 4  reg4++
  09  gtrr 4 2 5  reg4 > reg2
  10  addr 3 5 3  If above true goto 12
  11  seti 2 6 3  else goto 02
  12  addi 1 1 1  reg1++
  13  gtrr 1 2 5  reg1 > reg2
  14  addr 5 3 3  If above true Jump next to end
  15  seti 1 0 3  else goto 01
  16  mulr 3 3 3  End
#+END_EXAMPLE

After drawing a simple flow chart we can see that this part of the problem is simple finding two numbers reg1 and reg4 such that reg1 * reg4 is reg2, i.e., divisors of reg2. and when it finds them reg0 = reg0 + reg1. So *reg0 is sum of all divisors of reg2* i.e., (10551418).

** Day20
[2018-12-20 Thu]
Basic visualization done. Crude path length implementation partly done.
